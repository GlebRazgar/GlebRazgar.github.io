---
title: ""
date: 2021-10-02
layout: post
---


What I want to convay in this blog + Why:
AGI will be achieved not as an individual entity, but a composite system that gradually crosess the "threashold".
(ASI will be a year away from AGI)



AGI safety success will be downstream from gardrailing we design in the proccess of establishing multi-agent pipelines.
What should we focus on?
Table of contents:
How super intelligence currently functions in the society as a composition of lower level inteligent systems.
1.2 Introduce your argument about how AGI will be achieved.
1.3. Thought Experiment: "Employ the specialised chimp". Chimps iq ranges between 35-50. Gorillas 75-90. Imagine having multi-agents as specialised chimps.
1.4. Upscaling the specialised chimp. Now imagine chimps controlling most of our infrastructure.
P of doom if AI infrastructure will get built out like this.
How to align the systems.
1.
"What sphinx of cement and aluminum bashed open their skulls and ate up their brains and imagination?"

"Moloch whose mind is pure machinery! Moloch whose blood is running money! Moloch whose soul is electricity and banks! Moloch whose poverty is the specter of genius! Moloch whose fate is a cloud of sexless hydrogen! Moloch whose name is the Mind!"

"Moloch!"

In his famous poerm called Molog, Allen Ginsberg conceeds civilization as an individual entity. With Moloch and his "skyscraper-window eyes", "Moloch whose fingers are ten armies" "Moloch in whom I am a consciousness without a body!"

We make up for an emerging organism. One that is also suseptible to senses, and evolution. Societal mind virus becomes the organisms mental disorder. Nuclear bombs bruise its skin. And economic policies make for its evolutionary gradient.

The emergance, however, will not be limited to human societies. AGI will likely share such fait. Instead of being ascembled in a pandora's box, one might imagine the infrastructure that we design today to one day become conciouse, and in all likelyhood become conciouse faster than the AGI we can design in a lab.

To make it concrete think of you and I. In isolation, a human makes for an intelligent being. Together, the society makes for super intelligence.

Humans love predictions for they love gambling. Predictions not grounded in axioms almost always turn out to be false. To postulate about the uprise of AGI reasonably,